{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTLlW4hGG-Ei"
      },
      "outputs": [],
      "source": [
        "!pip install -qq onnx onnxscript onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import onnx\n",
        "import onnxruntime\n"
      ],
      "metadata": {
        "id": "r0WAieryHWYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "kpsLgQylKawm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN_Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(3, 6, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(6 * 7 * 7, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 6 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "EqY4H8mxHdSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "model = CNN_Model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6shrGEfKhTX",
        "outputId": "df426fad-7c71-494f-d986-2d02c051a09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "j3P-49YdMve3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANOvczRLK_iH",
        "outputId": "9cc2dbb1-2b16-49e9-ef83-2210cf752dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.1359\n",
            "Epoch [2/5], Loss: 0.0930\n",
            "Epoch [3/5], Loss: 0.0996\n",
            "Epoch [4/5], Loss: 0.2569\n",
            "Epoch [5/5], Loss: 0.1498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "2xdWyijeMwtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rGw8C3kMkAe",
        "outputId": "a60101b8-fad4-4ce5-c8d9-eb770300b989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export ONNX"
      ],
      "metadata": {
        "id": "YhN608P_M5W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "torch_input = torch.randn(2, 1, 28, 28)\n",
        "export_options = torch.onnx.ExportOptions(dynamic_shapes=True)\n",
        "onnx_program = torch.onnx.dynamo_export(model, torch_input,\n",
        "                                        export_options=export_options\n",
        "                                        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApFaFOqqHe0A",
        "outputId": "82ccae1b-fd05-41d7-c69c-60aaba8802a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/onnx/_internal/_exporter_legacy.py:116: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_program.save(\"cnn_model.onnx\")"
      ],
      "metadata": {
        "id": "TTS9cI1MITlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = onnx.load(\"cnn_model.onnx\")\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "metadata": {
        "id": "K7GhWufERE5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.onnx.export(\n",
        "#     model,\n",
        "#     torch_input,\n",
        "#     \"cnn_model_2.onnx\",\n",
        "#     input_names=[\"input\"],\n",
        "#     output_names=[\"output\"],\n",
        "#     dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
        "# )"
      ],
      "metadata": {
        "id": "TU4-FBSlV_GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute the ONNX model with ONNX Runtime"
      ],
      "metadata": {
        "id": "hft0Jt50RVYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_input = [torch.randn(2, 1, 28, 28),\n",
        "              torch.randn(5, 1, 28, 28),\n",
        "              torch.randn(3, 1, 28, 28)]\n",
        "print(f\"Input length: {len(onnx_input)}\")\n",
        "print(f\"Sample input: {onnx_input}\")\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\n",
        "    \"./cnn_model.onnx\",\n",
        "    providers=['CPUExecutionProvider',]\n",
        "    )\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "onnxruntime_input = {k.name: to_numpy(v)\n",
        "for k, v in zip(ort_session.get_inputs(), onnx_input)}\n",
        "\n",
        "# onnxruntime returns a list of outputs\n",
        "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KxxVbItlRWGK",
        "outputId": "c311aa7c-fc5c-4703-a3d7-40dc96f31c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input length: 3\n",
            "Sample input: [tensor([[[[ 0.6181,  0.8157,  2.5101,  ..., -0.7072, -1.1273, -1.3691],\n",
            "          [-1.5253, -1.5387,  0.7521,  ..., -0.4119, -0.1180, -0.8194],\n",
            "          [ 1.1372, -0.3255,  1.8639,  ...,  1.0781,  1.6716,  0.7560],\n",
            "          ...,\n",
            "          [-0.3478, -1.5809, -1.0452,  ..., -0.0446, -1.7842,  0.4616],\n",
            "          [ 1.9251, -0.2804, -2.8128,  ..., -0.5941,  0.6544,  0.8159],\n",
            "          [ 0.6301, -0.2596, -0.1456,  ..., -0.6066, -0.1811,  0.3224]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9361,  0.3533, -1.0349,  ...,  2.7408,  0.5204, -0.0874],\n",
            "          [ 1.8348,  0.6356,  1.6431,  ..., -0.4123, -0.9477,  0.6689],\n",
            "          [ 0.2274, -1.8075, -0.4096,  ...,  0.3364, -0.3241, -1.6592],\n",
            "          ...,\n",
            "          [-0.3595, -0.1504,  0.1568,  ..., -2.6497,  0.7735,  0.5589],\n",
            "          [ 0.6576,  0.2229,  0.4319,  ..., -0.1802,  0.4499, -0.8557],\n",
            "          [ 1.0354, -1.2581, -1.1112,  ...,  0.0964,  0.0570, -1.5447]]]]), tensor([[[[ 0.1661, -0.5909, -0.6635,  ...,  1.8527,  0.9053,  0.3717],\n",
            "          [ 1.1746,  1.2569,  0.3636,  ..., -0.5065, -0.0462, -0.0450],\n",
            "          [ 2.1024, -0.7509,  0.8287,  ...,  0.6562,  2.8038,  1.6030],\n",
            "          ...,\n",
            "          [ 0.8226, -0.6760,  0.4633,  ..., -0.5322,  0.5531, -2.0078],\n",
            "          [ 1.1953, -0.9455, -0.1450,  ...,  1.1171,  1.9688,  1.0382],\n",
            "          [-0.3184,  0.4684, -1.1745,  ..., -0.3708,  0.2819, -0.6863]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6656, -0.3911,  0.3630,  ..., -0.9174,  0.7239,  0.6303],\n",
            "          [ 0.1521,  0.6136, -0.2202,  ..., -0.0478,  0.3956, -0.0418],\n",
            "          [ 1.4018, -1.2609,  0.8487,  ...,  0.4674,  0.3598, -0.1905],\n",
            "          ...,\n",
            "          [-0.2239,  0.6748,  0.2471,  ...,  3.2146, -0.9376,  0.0934],\n",
            "          [ 0.3083,  1.0287,  1.0026,  ..., -1.0957, -0.1447,  0.2721],\n",
            "          [-1.7682,  0.5151,  0.6960,  ...,  0.1360,  1.9509,  0.0304]]],\n",
            "\n",
            "\n",
            "        [[[-0.3410, -1.6675,  1.8095,  ..., -1.1060, -0.0470, -0.0130],\n",
            "          [ 0.4569, -0.6431, -0.3607,  ...,  1.0972,  1.0853, -0.8181],\n",
            "          [-1.9976,  0.6433,  0.4521,  ..., -0.1205,  0.2736,  2.1437],\n",
            "          ...,\n",
            "          [-1.5597,  0.4407, -2.2026,  ...,  1.1742,  0.2087, -0.4414],\n",
            "          [ 0.1998, -0.4701,  1.0352,  ..., -0.1645, -0.5100, -0.5203],\n",
            "          [-0.8224, -0.6441, -1.4194,  ..., -0.4247,  0.2721,  0.6386]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3057, -0.4313, -1.5103,  ...,  1.0670, -0.2980,  1.2781],\n",
            "          [-1.2780,  0.3204,  1.8594,  ..., -1.0798, -0.2301,  0.7141],\n",
            "          [-0.6154, -0.4250,  0.2603,  ..., -1.4143,  1.6513, -2.3302],\n",
            "          ...,\n",
            "          [ 0.1519, -0.3027,  1.2262,  ...,  1.6265, -1.3549,  0.6186],\n",
            "          [ 0.0835, -0.0760, -1.0770,  ..., -0.6982,  0.8963,  0.1061],\n",
            "          [ 0.0851, -0.0754, -0.5337,  ..., -0.3611,  0.9329,  1.2459]]],\n",
            "\n",
            "\n",
            "        [[[-1.8968,  0.3922,  1.0027,  ..., -0.0315, -0.2485,  0.3686],\n",
            "          [-0.2661,  1.1135,  2.2956,  ..., -0.4539,  0.1410, -1.1985],\n",
            "          [-0.2577,  0.6157, -0.6936,  ...,  1.6840, -1.8474,  0.2108],\n",
            "          ...,\n",
            "          [ 0.1728,  1.4836, -0.3802,  ..., -1.4818,  0.2695, -1.6914],\n",
            "          [ 0.9265,  1.0556,  0.6168,  ..., -1.0846, -1.5948, -1.0116],\n",
            "          [-0.2189,  0.8617, -1.3897,  ..., -0.6954,  2.1565, -0.7928]]]]), tensor([[[[ 0.9053,  0.7405, -0.1376,  ...,  0.3696, -0.0627,  0.2771],\n",
            "          [-0.0320, -1.2141,  0.8584,  ...,  0.2304,  0.2861, -0.0302],\n",
            "          [-1.3743,  0.1705, -0.7719,  ...,  1.0569, -0.2347,  0.0784],\n",
            "          ...,\n",
            "          [ 1.0593,  0.2357,  0.0734,  ...,  0.9704, -0.4133,  0.8895],\n",
            "          [ 0.6545,  1.3909, -0.4909,  ...,  0.1215,  0.4527,  0.3212],\n",
            "          [ 1.9541, -0.0658, -0.0249,  ..., -0.0375, -0.4246,  0.9459]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3619,  1.3795, -1.5324,  ...,  1.4941, -1.6269, -0.0722],\n",
            "          [ 0.3091,  0.4029,  0.2895,  ...,  0.6920, -1.4215,  0.1587],\n",
            "          [ 1.2100,  0.8333, -2.2734,  ..., -2.2781, -1.4100, -2.4861],\n",
            "          ...,\n",
            "          [ 0.2366,  2.0278,  2.2597,  ..., -1.9158, -1.4153, -1.4227],\n",
            "          [ 0.8295, -0.1002,  0.0966,  ...,  0.4395,  0.3838,  0.0463],\n",
            "          [ 1.3106, -0.9647,  3.1604,  ...,  0.3530,  0.3137, -0.0573]]],\n",
            "\n",
            "\n",
            "        [[[-0.0503,  0.4524, -0.1318,  ..., -1.4893, -0.0658,  2.4470],\n",
            "          [-0.6350, -1.3042,  1.5906,  ...,  1.3625, -0.3489,  1.0333],\n",
            "          [-0.3774, -1.4061, -2.5493,  ..., -0.1176, -0.8791, -1.9842],\n",
            "          ...,\n",
            "          [-0.0745,  0.0120, -0.4910,  ...,  1.3634,  0.9594, -0.7049],\n",
            "          [-1.4244,  1.0240, -1.3343,  ..., -0.1659,  0.1062, -0.7355],\n",
            "          [-0.5056, -0.3269, -0.0373,  ..., -0.9733,  0.2112,  0.5054]]]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        images_np = {k.name: to_numpy(v)\n",
        "for k, v in zip(ort_session.get_inputs(), [images])}\n",
        "\n",
        "        outputs = ort_session.run(None, images_np)\n",
        "        outputs = torch.tensor(outputs[0])\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.cpu()).sum().item()\n",
        "\n",
        "print(f'Test Accuracy with ONNX Runtime: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVL9ymcwSXQX",
        "outputId": "52be4133-e542-4637-f729-000780fc8e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy with ONNX Runtime: 97.40%\n"
          ]
        }
      ]
    }
  ]
}